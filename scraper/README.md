# Steam Scraper + Vectorizaci√≥n

Pipeline completo de scraping de juegos de Steam con generaci√≥n autom√°tica de embeddings sem√°nticos y sincronizaci√≥n remota para an√°lisis RAG (Retrieval-Augmented Generation).

## üéØ ¬øQu√© hace este proyecto?

1. **Scraping inteligente**: Descarga datos de ~5,000 juegos de Steam (trending + cl√°sicos populares)
2. **Filtrado autom√°tico**: Elimina DLC, soundtracks y contenido adulto (filter-games.py)
3. **Extracci√≥n de descripciones**: Obtiene descripciones detalladas de la Steam API (imp-futuras)
4. **Res√∫menes IA**: Genera res√∫menes con OpenRouter GPT-4o-mini (imp-futuras)
5. **Reemplazo inteligente**: Integra descripciones resumidas en los datos principales (desc-changer.py)
6. **Vectorizaci√≥n sem√°ntica**: Genera embeddings de 768 dimensiones con modelos multiling√ºes para b√∫squeda por similitud
7. **Pipeline automatizado**: Orquesta todas las fases ‚Üí limpieza ‚Üí vectorizaci√≥n ‚Üí sincronizaci√≥n remota
8. **Sincronizaci√≥n SSH**: Copia autom√°tica de datos vectorizados y logs a servidor remoto para ingesti√≥n en Elasticsearch/Logstash

## üìÅ Estructura del Proyecto

```
scraper/
‚îú‚îÄ‚îÄ scripts/                       # Scripts del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ run_pipeline.py            # Orquestador principal (scraping ‚Üí limpieza)
‚îÇ   ‚îú‚îÄ‚îÄ gameid-script.py           # Fase 1: Descarga IDs de juegos populares
‚îÇ   ‚îú‚îÄ‚îÄ sacar-datos-games.py       # Fase 2: Obtiene detalles completos (identificador de IDs ya procesados) + limpieza HTML
‚îÇ   ‚îú‚îÄ‚îÄ filter-games.py            # Fase 2.5: Filtra DLC, soundtracks y contenido adulto
‚îÇ   ‚îú‚îÄ‚îÄ clean-tags.py              # Fase 3: Limpia categor√≠as/tags irrelevantes
‚îÇ   ‚îú‚îÄ‚îÄ desc-changer.py            # Fase 3.5: Reemplaza descripciones con res√∫menes IA
‚îÇ   ‚îú‚îÄ‚îÄ vectorizador.py            # Fase 4: Genera embeddings (768 dims)
‚îÇ   ‚îî‚îÄ‚îÄ instalar_modelo.py         # Descargador de modelos SentenceTransformers
‚îú‚îÄ‚îÄ sh_test/                       # Scripts auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ cp-vects.sh                # Sincronizaci√≥n manual a servidor remoto
‚îú‚îÄ‚îÄ data/                          # Datos generados (ignorados por git)
‚îÇ   ‚îú‚îÄ‚îÄ steam-top-games.json       # IDs de juegos filtrados (5,001+)
‚îÇ   ‚îú‚îÄ‚îÄ steam-games-data.ndjson    # Datos completos con descripciones resumidas
‚îÇ   ‚îî‚îÄ‚îÄ steam-games-data-vect.ndjson # Datos + embeddings 768-dim (listo para RAG)
‚îú‚îÄ‚îÄ backups/                       # Copias de seguridad (ej. steam-top-games-*.json)
‚îú‚îÄ‚îÄ logs/                          # Logs del pipeline (ignorados por git)
‚îÇ   ‚îú‚îÄ‚îÄ scraper_metrics.log        # Logs de gameid-script.py
‚îÇ   ‚îú‚îÄ‚îÄ scraper_full_data_metrics.log # Logs de sacar-datos-games.py
‚îÇ   ‚îî‚îÄ‚îÄ setup_fail.log             # Registro de fallos del instalador
‚îú‚îÄ‚îÄ .vscode/                       # Configuraci√≥n local del editor
‚îú‚îÄ‚îÄ setup.sh                       # Instalador completo Linux (ejecuta pipeline)
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias (requests, beautifulsoup4, torch CPU, sentence-transformers, openai, etc.)
‚îú‚îÄ‚îÄ .gitignore                     # Ignora data/, logs/, .venv/, caches
‚îî‚îÄ‚îÄ README.md                      # Este archivo
```

## üöÄ Instalaci√≥n R√°pida

### Linux/Mac (Setup completo)
```bash
cd /home/g6/reto/scraper
chmod +x setup.sh
./setup.sh
```

**El script `setup.sh` ejecuta autom√°ticamente:**
1. ‚úÖ Verificaci√≥n de Python3 disponible
2. ‚úÖ **Uso del venv global unificado** (`/home/g6/.venv`) - compartido con imp-futuras
3. ‚úÖ Instalaci√≥n de dependencias desde `requirements.txt` (torch CPU, sentence-transformers, openai)
4. ‚úÖ Verificaci√≥n de PyTorch CPU + sentence-transformers mediante import check
5. ‚úÖ Descarga del modelo de embeddings (paraphrase-multilingual-mpnet-base-v2, con verificaci√≥n de cach√© en `~/.cache/huggingface/`)
6. ‚úÖ **Sincronizaci√≥n de datos con Elasticsearch** (fase nueva)
7. ‚úÖ Scraping de Steam (run_pipeline.py)
8. ‚úÖ Filtrado de DLC/soundtracks (filter-games.py)
9. ‚úÖ Limpieza de categor√≠as Steam (clean-tags.py)
10. ‚úÖ Extracci√≥n de descripciones + res√∫menes IA (flux.sh en imp-futuras)
11. ‚úÖ Reemplazo de descripciones (desc-changer.py)
12. ‚úÖ Vectorizaci√≥n sem√°ntica (vectorizador.py)
13. ‚úÖ **Sincronizaci√≥n incremental de datos** (cargar IDs existentes, eliminar obsoletos, reprocesar v√°lidos)
14. ‚úÖ Sincronizaci√≥n SSH a servidor remoto con validaci√≥n de directorio (`192.199.1.65:/home/g6/reto/datos/`)

### Instalaci√≥n manual (paso a paso)

Si prefieres instalar manualmente:

```bash
# 1. Usar entorno virtual global (crear si no existe)
python3 -m venv /home/g6/.venv
source /home/g6/.venv/bin/activate

# 2. Instalar dependencias (incluye torch CPU, sentence-transformers, openai)
cd /home/g6/reto/scraper
pip install -r requirements.txt

# 3. Verificar instalaci√≥n de librer√≠as cr√≠ticas
python -c "import torch, sentence_transformers, openai; print('‚úÖ OK')"

# 4. Descargar modelo de embeddings (si no est√° en cach√©)
python scripts/instalar_modelo.py
```

### Actualizaci√≥n de un entorno existente

Si ya tienes `/home/g6/.venv` pero necesitas actualizar dependencias:

```bash
source /home/g6/.venv/bin/activate
cd /home/g6/reto/scraper
pip install --upgrade -r requirements.txt
```

## ‚ñ∂Ô∏è Ejecuci√≥n del Pipeline

### Ejecuci√≥n completa (recomendado)
```bash
source /home/g6/.venv/bin/activate
python scripts/run_pipeline.py  # Scraping + limpieza
terminal -> /home/g6/reto/imp-futuras/flux.sh # Ejecucion del flujo (Resumenes LLM)
python scripts/desc-changer.py  # Cambio de descripciones viejas a nuevas
python scripts/vectorizador.py  # Generaci√≥n de embeddings
bash sh_test/cp-vects.sh        # Sincronizaci√≥n remota (opcional)
```

### Ejecuci√≥n individual de scripts

**Fase 1: Obtener IDs de juegos**
```bash
python scripts/gameid-script.py
# Salida: data/steam-top-games.json (~5k IDs)
```

**Fase 2: Descargar datos completos**
```bash
python scripts/sacar-datos-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-games-data.ndjson (t√≠tulo, descripci√≥n, g√©neros, precio, etc.)
# 
# Cambios recientes:
# - Sincronizaci√≥n incremental: Compara IDs con archivo NDJSON existente
# - Elimina juegos obsoletos (ya no en top games)
# - Reprocesa todos los v√°lidos para actualizar precios/m√©tricas
# - Log de cambios: "SINCRONIZACI√ìN | Eliminados:X | A reprocesar:Y"
```

**Fase 2.5: Filtrar DLC, soundtracks y contenido adulto**
```bash
python scripts/filter-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-top-games-filtered.json (+ backup en backups/)
```

**Fase 3: Extracci√≥n de descripciones y generaci√≥n de res√∫menes IA (flux.sh)**
```bash
cd /home/g6/reto/imp-futuras
bash flux.sh  # Usa el mismo venv global /home/g6/.venv
# Salida: res√∫menes IA en imp-futuras/data que luego usa desc-changer.py
```

**Fase 3.5: Reemplazar descripciones con res√∫menes IA**
```bash
python scripts/desc-changer.py
# Entrada: data/steam-games-data.ndjson + res√∫menes IA de imp-futuras
# Salida: data/steam-games-data.ndjson (actualizado con res√∫menes)
```

**Fase 4: Generar embeddings**
```bash
python scripts/vectorizador.py
# Entrada: data/steam-games-data.ndjson
# Salida: data/steam-games-data-vect.ndjson (+ campo vector_embedding: float[768])
```

## üß≠ Orden del pipeline (setup.sh)

1) Verificaci√≥n de Python + venv global `/home/g6/.venv`
2) Instalaci√≥n/verificaci√≥n de dependencias (torch CPU, sentence-transformers, openai)
3) Descarga/validaci√≥n del modelo de embeddings (cache HF)
4) `run_pipeline.py` ‚Üí gameid-script.py + sacar-datos-games.py (con sincronizaci√≥n incremental)
5) `filter-games.py` ‚Üí filtra DLC/adulto y guarda `steam-top-games-filtered.json`
6) `imp-futuras/flux.sh` ‚Üí genera res√∫menes IA (OpenRouter)
7) `desc-changer.py` ‚Üí inserta res√∫menes IA en NDJSON principal
8) `clean-tags.py` ‚Üí limpia categor√≠as/tags irrelevantes
9) `vectorizador.py` ‚Üí genera embeddings 768D
10) `scp` opcional ‚Üí sincroniza NDJSON vectorizado + logs a 192.199.1.65

## üìä Formato de Salida (NDJSON)

Cada juego en `steam-games-data-vect.ndjson` es una l√≠nea JSON con:

```json
{
  "appid": 730,
  "name": "Counter-Strike 2",
  "scraped_at": "2025-12-10 08:20:50",
  "price_eur": 0.00,
  "price_initial_eur": 0.0, 
  "discount_pct": 0,
  "metacritic_score": 0, // no tiene score
  "recommendations_total": 4810260,
  "achievements_count": 1, 
  "is_free": true,
  "genres": ["Action", "FPS"],
  "categories": ["FPS", "Disparos", "Multijugador", "Competitivos" ...], 
  "developers": ["Valve"], 
  "publishers": ["Valve"], 
  "achievements_list": ["Una nueva era"],
  "short_description": "For over two decades...",
  "detailed_description": "Counter-Strike 2 es un videojuego de disparos competitivo...",
  "vector_embedding": [0.0234, -0.1234, ..., 0.0567]  // 768 floats
}

```

**Campo clave:** `vector_embedding` ‚Üí Vector de 768 dimensiones para b√∫squeda sem√°ntica en Elasticsearch con modelo dense_vector.

**Nota:** `detailed_description` ahora contiene un resumen IA generado con OpenRouter GPT-4o-mini (m√°s conciso que la descripci√≥n original).

## üîß Configuraci√≥n

### Entorno Virtual Global

El proyecto utiliza un **venv unificado** en `/home/g6/.venv` compartido entre `scraper` e `imp-futuras`:

```bash
# Activar siempre desde aqu√≠
source /home/g6/.venv/bin/activate

# Localizaci√≥n de binarios Python
/home/g6/.venv/bin/python
/home/g6/.venv/bin/pip

# Cach√© de modelos HuggingFace
~/.cache/huggingface/hub/  # (descargado autom√°ticamente)
```

**Ventajas:**
- ‚úÖ Una √∫nica instalaci√≥n de librer√≠as pesadas (torch, transformers)
- ‚úÖ Ahorra ~3-4 GB de espacio en disco
- ‚úÖ Coherencia en versiones entre scraper e API
- ‚úÖ Facilita mantenimiento centralizado

### Sincronizaci√≥n Incremental de Datos

El script `sacar-datos-games.py` implementa sincronizaci√≥n inteligente:

```python
# Fase autom√°tica en cada ejecuci√≥n:
1. cargar_ids_desde_ndjson()
   - Lee IDs existentes en steam-games-data.ndjson
   - Retorna set de IDs para comparaci√≥n

2. sincronizar_datos(lista_entrada, archivo_salida)
   - Compara IDs nuevos vs existentes
   - Elimina registros de juegos que bajaron del top
   - Reprocesa TODO juegos v√°lidos (actualizar precios/m√©tricas)
   - Log de cambios realizados

# Resultado:
- Archivo NDJSON siempre contiene juegos del top actual
- Precios siempre actualizados (ninguno es saltado)
- Juegos obsoletos eliminados autom√°ticamente
```

### Ajustar cantidad de juegos
- `scripts/gameid-script.py` ‚Üí `CANTIDAD_POR_CRITERIO = 5000` (IDs por criterio)
- `scripts/sacar-datos-games.py` ‚Üí `CANTIDAD_A_PROCESAR = 0` (0 = todos, cambiar a X para pruebas)

### Palabras clave para filtrado
Edita `scripts/filter-games.py` para cambiar qu√© se filtra (DLC, soundtracks, etc.)

### Configurar res√∫menes IA
Configura la API key de OpenRouter en `/home/g6/reto/imp-futuras/.env` para activar generaci√≥n autom√°tica de res√∫menes

### Cambiar modelo de embeddings
Edita `scripts/instalar_modelo.py` y `scripts/vectorizador.py`:
```python
# Opciones:
# - 'all-mpnet-base-v2' (ingl√©s, 768 dims)
# - 'paraphrase-multilingual-mpnet-base-v2' (multiling√ºe, 768 dims) ‚Üê ACTUAL
# - 'all-MiniLM-L6-v2' (ingl√©s, 384 dims, m√°s r√°pido)
MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'
```

### Configurar sincronizaci√≥n remota
Edita `setup.sh` o `sh_test/cp-vects.sh`:
```bash
MAQUINA_REMOTA="192.199.1.65"
RUTA_REMOTA="/home/g6/reto/datos"
```

## ü§ñ Automatizaci√≥n con Crontab

Ejecutar pipeline diario a las 2:00 AM:
```bash
crontab -e
```

A√±ade:
```cron
0 2 * * * cd /home/g6/reto/scraper && /home/g6/.venv/bin/python scripts/run_pipeline.py >> /home/g6/reto/scraper/logs/cron.log 2>&1 && /home/g6/.venv/bin/python scripts/vectorizador.py >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

O ejecuta el setup completo (verifica instalaciones + ejecuta pipeline):
```cron
0 2 * * * cd /home/g6/reto/scraper && bash setup.sh >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

## üìù Logs y Debugging

- `logs/scraper_metrics.log` ‚Üí Peticiones HTTP, latencias, errores de conexi√≥n (Fase 1)
- `logs/scraper_full_data_metrics.log` ‚Üí Peticiones HTTP, parseos exitosos (Fase 2)
- `logs/setup_fail.log` ‚Üí Fallos del instalador (setup.sh)
- Logs en consola: `tail -f logs/scraper_metrics.log`

## üîí Seguridad y Requisitos

- **SSH sin contrase√±a** requerido para sincronizaci√≥n remota (usa `ssh-copy-id 192.199.1.65`)
- **Espacio en disco**: ~5-6 GB (venv global 2GB + modelo 470MB + datos 2-3GB)
- **Python 3.8+** requerido (testeado con Python 3.12.3)
- **Venv global**: `/home/g6/.venv` **obligatorio** - compartido entre scraper e imp-futuras
- **Librer√≠as CPU-only**: PyTorch sin CUDA para ahorrar espacio (~4 GB menos que versi√≥n GPU)
- **Modelos en cach√©**: `~/.cache/huggingface/hub/` se crea autom√°ticamente (~470MB)

## üõ†Ô∏è Tecnolog√≠as

- **Scraping**: `requests` + `BeautifulSoup4`
- **Embeddings**: `sentence-transformers` (HuggingFace)
- **Modelo**: `paraphrase-multilingual-mpnet-base-v2` (278M par√°metros, 768 dims)
- **Backend ML**: PyTorch (CPU-only)
- **Res√∫menes IA**: OpenRouter (GPT-4o-mini) con parallelizaci√≥n
- **Formato de datos**: NDJSON (compatible con Filebeat/Logstash/Elasticsearch)
