# Steam Scraper + VectorizaciÃ³n

Pipeline completo de scraping de juegos de Steam con generaciÃ³n automÃ¡tica de embeddings semÃ¡nticos y sincronizaciÃ³n remota para anÃ¡lisis RAG (Retrieval-Augmented Generation).

## ğŸ¯ Â¿QuÃ© hace este proyecto?

1. **Scraping inteligente**: Descarga datos de ~10,000 juegos de Steam (trending + clÃ¡sicos populares)
2. **VectorizaciÃ³n semÃ¡ntica**: Genera embeddings de 768 dimensiones con modelos multilingÃ¼es para bÃºsqueda por similitud
3. **Pipeline automatizado**: Orquesta scraping â†’ limpieza â†’ vectorizaciÃ³n â†’ sincronizaciÃ³n remota
4. **SincronizaciÃ³n SSH**: Copia automÃ¡tica de datos vectorizados y logs a servidor remoto para ingestiÃ³n en Elasticsearch/Logstash

## ğŸ“ Estructura del Proyecto

```
scraper/
â”œâ”€â”€ scripts/                       # Scripts del pipeline
â”‚   â”œâ”€â”€ run_pipeline.py            # Orquestador principal (scraping â†’ limpieza)
â”‚   â”œâ”€â”€ gameid-script.py           # Fase 1: Descarga IDs de juegos populares
â”‚   â”œâ”€â”€ sacar-datos-games.py       # Fase 2: Obtiene detalles completos + limpieza HTML
â”‚   â”œâ”€â”€ vectorizador.py            # Fase 3: Genera embeddings (modelo all-mpnet-base-v2)
â”‚   â”œâ”€â”€ vectorizador2.py           # Alternativa: modelo multilingÃ¼e paraphrase-multilingual
â”‚   â””â”€â”€ instalar_modelo.py         # Descargador de modelos SentenceTransformers
â”œâ”€â”€ sh_test/                       # Scripts auxiliares de setup
â”‚   â”œâ”€â”€ instalar_lib_embeddings.sh # Instala PyTorch CPU + sentence-transformers
â”‚   â””â”€â”€ cp-vects.sh                # SincronizaciÃ³n manual a servidor remoto
â”œâ”€â”€ data/                          # Datos generados (ignorados por git)
â”‚   â”œâ”€â”€ steam-top-games.json       # ~10k IDs de juegos (salida Fase 1)
â”‚   â”œâ”€â”€ steam-games-data.ndjson    # Datos completos sin vectorizar (Fase 2)
â”‚   â””â”€â”€ steam-games-data-vect.ndjson # Datos + embeddings (Fase 3, listo para RAG)
â”œâ”€â”€ logs/                          # Logs del pipeline (ignorados por git)
â”‚   â”œâ”€â”€ scraper_metrics.log        # Logs de gameid-script.py
â”‚   â”œâ”€â”€ scraper_full_data_metrics.log # Logs de sacar-datos-games.py
â”‚   â””â”€â”€ setup_fail.log             # Registro de fallos del instalador
â”œâ”€â”€ .venv/                         # Entorno virtual Python
â”œâ”€â”€ setup.sh                       # Instalador completo Linux/Mac (ejecuta pipeline)
â”œâ”€â”€ requirements.txt               # Dependencias base (requests, beautifulsoup4, etc.)
â”œâ”€â”€ .gitignore                     # Ignora data/, logs/, .venv/, caches
â””â”€â”€ README.md                      # Este archivo
```

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Linux/Mac (Setup completo)
```bash
cd /home/g6/reto/scraper
chmod +x setup.sh
./setup.sh
```

**El script `setup.sh` ejecuta automÃ¡ticamente:**
1. âœ… VerificaciÃ³n de Python3 y venv
2. âœ… CreaciÃ³n de `.venv/` y activaciÃ³n
3. âœ… InstalaciÃ³n de dependencias (`requirements.txt`)
4. âœ… InstalaciÃ³n de PyTorch CPU + sentence-transformers
5. âœ… Descarga del modelo de embeddings (paraphrase-multilingual-mpnet-base-v2)
6. âœ… EjecuciÃ³n del pipeline completo (scraping + vectorizaciÃ³n)
7. âœ… SincronizaciÃ³n SSH a servidor remoto (`192.199.1.65:/home/g6/reto/datos/`)

**Nota:** Si todo estÃ¡ instalado, solo ejecuta los pasos 6-7 (ideal para cron jobs).

### InstalaciÃ³n manual (paso a paso)

Si prefieres instalar manualmente:

```bash
# 1. Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate

# 2. Instalar dependencias base
pip install -r requirements.txt

# 3. Instalar librerÃ­as de embeddings (PyTorch CPU + SentenceTransformers)
bash sh_test/instalar_lib_embeddings.sh

# 4. Descargar modelo de embeddings
python scripts/instalar_modelo.py
```

## â–¶ï¸ EjecuciÃ³n del Pipeline

### EjecuciÃ³n completa (recomendado)
```bash
source .venv/bin/activate
python scripts/run_pipeline.py  # Scraping + limpieza
python scripts/vectorizador.py  # GeneraciÃ³n de embeddings
bash sh_test/cp-vects.sh        # SincronizaciÃ³n remota (opcional)
```

### EjecuciÃ³n individual de scripts

**Fase 1: Obtener IDs de juegos**
```bash
python scripts/gameid-script.py
# Salida: data/steam-top-games.json (~10k IDs)
```

**Fase 2: Descargar datos completos**
```bash
python scripts/sacar-datos-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-games-data.ndjson (tÃ­tulo, descripciÃ³n, gÃ©neros, precio, etc.)
```

**Fase 3: Generar embeddings**
```bash
python scripts/vectorizador.py
# Entrada: data/steam-games-data.ndjson
# Salida: data/steam-games-data-vect.ndjson (+ campo vector_embedding: float[768])
```

## ğŸ“Š Formato de Salida (NDJSON)

Cada juego en `steam-games-data-vect.ndjson` es una lÃ­nea JSON con:

```json
{
  "appid": 730,
  "name": "Counter-Strike 2",
  "short_description": "For over two decades...",
  "detailed_description": "<p>For over two decades...</p>",
  "genres": ["Action", "FPS"],
  "categories": ["Multi-player", "Online PvP"],
  "developers": ["Valve"],
  "price_eur": "0.00",
  "vector_embedding": [0.0234, -0.1234, ..., 0.0567]  // 768 floats
}
```

**Campo clave:** `vector_embedding` â†’ Vector de 768 dimensiones para bÃºsqueda semÃ¡ntica en Elasticsearch con modelo dense_vector.

## ğŸ”§ ConfiguraciÃ³n

### Ajustar cantidad de juegos
- `scripts/gameid-script.py` â†’ `CANTIDAD_POR_CRITERIO = 5000` (IDs por criterio)
- `scripts/sacar-datos-games.py` â†’ `CANTIDAD_A_PROCESAR = 25` (0 = todos)

### Cambiar modelo de embeddings
Edita `scripts/instalar_modelo.py` y `scripts/vectorizador.py`:
```python
# Opciones:
# - 'all-mpnet-base-v2' (inglÃ©s, 768 dims)
# - 'paraphrase-multilingual-mpnet-base-v2' (multilingÃ¼e, 768 dims)
# - 'all-MiniLM-L6-v2' (inglÃ©s, 384 dims, mÃ¡s rÃ¡pido)
MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'
```

### Configurar sincronizaciÃ³n remota
Edita `setup.sh` o `sh_test/cp-vects.sh`:
```bash
MAQUINA_REMOTA="192.199.1.65"
RUTA_REMOTA="/home/g6/reto/datos"
```

## ğŸ¤– AutomatizaciÃ³n con Crontab

Ejecutar pipeline diario a las 2:00 AM:
```bash
crontab -e
```

AÃ±ade:
```cron
0 2 * * * cd /home/g6/reto/scraper && /home/g6/reto/scraper/.venv/bin/python scripts/run_pipeline.py >> /home/g6/reto/scraper/logs/cron.log 2>&1 && /home/g6/reto/scraper/.venv/bin/python scripts/vectorizador.py >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

O ejecuta el setup completo (verifica instalaciones + ejecuta pipeline):
```cron
0 2 * * * cd /home/g6/reto/scraper && bash setup.sh >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

## ğŸ“ Logs y Debugging

- `logs/scraper_metrics.log` â†’ Peticiones HTTP, latencias, errores de conexiÃ³n (Fase 1)
- `logs/scraper_full_data_metrics.log` â†’ Peticiones HTTP, parseos exitosos (Fase 2)
- `logs/setup_fail.log` â†’ Fallos del instalador (setup.sh)
- Logs en consola: `tail -f logs/scraper_metrics.log`

## ğŸ”’ Seguridad y Requisitos

- **SSH sin contraseÃ±a** requerido para sincronizaciÃ³n remota (usa `ssh-copy-id 192.199.1.65`)
- **Espacio en disco**: ~4-5 GB (modelo + datos + cache pip/huggingface)
- **Python 3.8+** requerido
- **LibrerÃ­as CPU-only**: PyTorch sin CUDA para ahorrar espacio (~2 GB menos que versiÃ³n GPU)

## ğŸ› ï¸ TecnologÃ­as

- **Scraping**: `requests` + `BeautifulSoup4`
- **Embeddings**: `sentence-transformers` (HuggingFace)
- **Modelo**: `paraphrase-multilingual-mpnet-base-v2` (278M parÃ¡metros, 768 dims)
- **Backend ML**: PyTorch (CPU-only)
- **Formato de datos**: NDJSON (compatible con Filebeat/Logstash/Elasticsearch)


.