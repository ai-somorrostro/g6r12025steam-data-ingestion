# Steam Scraper + Vectorizaci√≥n

Pipeline completo de scraping de juegos de Steam con generaci√≥n autom√°tica de embeddings sem√°nticos y sincronizaci√≥n remota para an√°lisis RAG (Retrieval-Augmented Generation).

## üéØ ¬øQu√© hace este proyecto?

1. **Scraping inteligente**: Descarga datos de ~10,000 juegos de Steam (trending + cl√°sicos populares)
2. **Filtrado autom√°tico**: Elimina DLC, soundtracks y contenido adulto (filter-games.py)
3. **Extracci√≥n de descripciones**: Obtiene descripciones detalladas de la Steam API (imp-futuras)
4. **Res√∫menes IA**: Genera res√∫menes con OpenRouter GPT-4o-mini (imp-futuras)
5. **Reemplazo inteligente**: Integra descripciones resumidas en los datos principales (desc-changer.py)
6. **Vectorizaci√≥n sem√°ntica**: Genera embeddings de 768 dimensiones con modelos multiling√ºes para b√∫squeda por similitud
7. **Pipeline automatizado**: Orquesta todas las fases ‚Üí limpieza ‚Üí vectorizaci√≥n ‚Üí sincronizaci√≥n remota
8. **Sincronizaci√≥n SSH**: Copia autom√°tica de datos vectorizados y logs a servidor remoto para ingesti√≥n en Elasticsearch/Logstash

## üìÅ Estructura del Proyecto

```
scraper/
‚îú‚îÄ‚îÄ scripts/                       # Scripts del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ run_pipeline.py            # Orquestador principal (scraping ‚Üí limpieza)
‚îÇ   ‚îú‚îÄ‚îÄ gameid-script.py           # Fase 1: Descarga IDs de juegos populares
‚îÇ   ‚îú‚îÄ‚îÄ sacar-datos-games.py       # Fase 2: Obtiene detalles completos + limpieza HTML
‚îÇ   ‚îú‚îÄ‚îÄ filter-games.py            # Fase 2.5: Filtra DLC, soundtracks y contenido adulto
‚îÇ   ‚îú‚îÄ‚îÄ desc-changer.py            # Fase 3.5: Reemplaza descripciones con res√∫menes IA
‚îÇ   ‚îú‚îÄ‚îÄ vectorizador.py            # Fase 4: Genera embeddings (768 dims)
‚îÇ   ‚îú‚îÄ‚îÄ vectorizador2.py           # Alternativa: modelo multiling√ºe paraphrase-multilingual
‚îÇ   ‚îî‚îÄ‚îÄ instalar_modelo.py         # Descargador de modelos SentenceTransformers
‚îú‚îÄ‚îÄ sh_test/                       # Scripts auxiliares de setup
‚îÇ   ‚îú‚îÄ‚îÄ instalar_lib_embeddings.sh # Instala PyTorch CPU + sentence-transformers
‚îÇ   ‚îî‚îÄ‚îÄ cp-vects.sh                # Sincronizaci√≥n manual a servidor remoto
‚îú‚îÄ‚îÄ data/                          # Datos generados (ignorados por git)
‚îÇ   ‚îú‚îÄ‚îÄ steam-top-games.json       # IDs de juegos filtrados (5,001+)
‚îÇ   ‚îú‚îÄ‚îÄ steam-games-data.ndjson    # Datos completos con descripciones resumidas
‚îÇ   ‚îî‚îÄ‚îÄ steam-games-data-vect.ndjson # Datos + embeddings 768-dim (listo para RAG)
‚îú‚îÄ‚îÄ logs/                          # Logs del pipeline (ignorados por git)
‚îÇ   ‚îú‚îÄ‚îÄ scraper_metrics.log        # Logs de gameid-script.py
‚îÇ   ‚îú‚îÄ‚îÄ scraper_full_data_metrics.log # Logs de sacar-datos-games.py
‚îÇ   ‚îî‚îÄ‚îÄ setup_fail.log             # Registro de fallos del instalador
‚îú‚îÄ‚îÄ .venv/                         # Entorno virtual Python
‚îú‚îÄ‚îÄ setup.sh                       # Instalador completo Linux/Mac (ejecuta pipeline)
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias base (requests, beautifulsoup4, etc.)
‚îú‚îÄ‚îÄ .gitignore                     # Ignora data/, logs/, .venv/, caches
‚îî‚îÄ‚îÄ README.md                      # Este archivo
```

## üöÄ Instalaci√≥n R√°pida

### Linux/Mac (Setup completo)
```bash
cd /home/g6/reto/scraper
chmod +x setup.sh
./setup.sh
```

**El script `setup.sh` ejecuta autom√°ticamente:**
1. ‚úÖ Verificaci√≥n de Python3 y venv
2. ‚úÖ Creaci√≥n de `.venv/` y activaci√≥n
3. ‚úÖ Instalaci√≥n de dependencias (`requirements.txt`)
4. ‚úÖ Instalaci√≥n de PyTorch CPU + sentence-transformers
5. ‚úÖ Descarga del modelo de embeddings (paraphrase-multilingual-mpnet-base-v2)
6. ‚úÖ Scraping de Steam (run_pipeline.py)
7. ‚úÖ Filtrado de DLC/soundtracks (filter-games.py)
8. ‚úÖ Extracci√≥n de descripciones + res√∫menes IA (carpeta imp-futuras)
9. ‚úÖ Reemplazo de descripciones (desc-changer.py)
10. ‚úÖ Vectorizaci√≥n sem√°ntica (vectorizador.py)
11. ‚úÖ Sincronizaci√≥n SSH a servidor remoto (`192.199.1.65:/home/g6/reto/datos/`)

### Instalaci√≥n manual (paso a paso)

Si prefieres instalar manualmente:

```bash
# 1. Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate

# 2. Instalar dependencias base
pip install -r requirements.txt

# 3. Instalar librer√≠as de embeddings (PyTorch CPU + SentenceTransformers)
bash sh_test/instalar_lib_embeddings.sh

# 4. Descargar modelo de embeddings
python scripts/instalar_modelo.py
```

## ‚ñ∂Ô∏è Ejecuci√≥n del Pipeline

### Ejecuci√≥n completa (recomendado)
```bash
source .venv/bin/activate
python scripts/run_pipeline.py  # Scraping + limpieza
python scripts/vectorizador.py  # Generaci√≥n de embeddings
bash sh_test/cp-vects.sh        # Sincronizaci√≥n remota (opcional)
```

### Ejecuci√≥n individual de scripts

**Fase 1: Obtener IDs de juegos**
```bash
python scripts/gameid-script.py
# Salida: data/steam-top-games.json (~10k IDs)
```

**Fase 2: Descargar datos completos**
```bash
python scripts/sacar-datos-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-games-data.ndjson (t√≠tulo, descripci√≥n, g√©neros, precio, etc.)
```

**Fase 2.5: Filtrar DLC, soundtracks y contenido adulto**
```bash
python scripts/filter-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-top-games.json (filtrada, ~5,001 juegos)
```

**Fase 3: Extracci√≥n de descripciones y generaci√≥n de res√∫menes IA**
```bash
# Ejecutado desde la carpeta imp-futuras (scripts de extracci√≥n + OpenRouter)
```

**Fase 3.5: Reemplazar descripciones con res√∫menes IA**
```bash
python scripts/desc-changer.py
# Entrada: data/steam-games-data.ndjson + res√∫menes IA de imp-futuras
# Salida: data/steam-games-data.ndjson (actualizado con res√∫menes)
```

**Fase 4: Generar embeddings**
```bash
python scripts/vectorizador.py
# Entrada: data/steam-games-data.ndjson
# Salida: data/steam-games-data-vect.ndjson (+ campo vector_embedding: float[768])
```

## üìä Formato de Salida (NDJSON)

Cada juego en `steam-games-data-vect.ndjson` es una l√≠nea JSON con:

```json
{
  "appid": 730,
  "name": "Counter-Strike 2",
  "short_description": "For over two decades...",
  "detailed_description": "Counter-Strike 2 es un videojuego de disparos competitivo...",
  "genres": ["Action", "FPS"],
  "categories": ["Multi-player", "Online PvP"],
  "developers": ["Valve"],
  "price_eur": "0.00",
  "vector_embedding": [0.0234, -0.1234, ..., 0.0567]  // 768 floats
}
```

**Campo clave:** `vector_embedding` ‚Üí Vector de 768 dimensiones para b√∫squeda sem√°ntica en Elasticsearch con modelo dense_vector.

**Nota:** `detailed_description` ahora contiene un resumen IA generado con OpenRouter GPT-4o-mini (m√°s conciso que la descripci√≥n original).

## üîß Configuraci√≥n

### Ajustar cantidad de juegos
- `scripts/gameid-script.py` ‚Üí `CANTIDAD_POR_CRITERIO = 5000` (IDs por criterio)
- `scripts/sacar-datos-games.py` ‚Üí `CANTIDAD_A_PROCESAR = 25` (0 = todos)

### Palabras clave para filtrado
Edita `scripts/filter-games.py` para cambiar qu√© se filtra (DLC, soundtracks, etc.)

### Configurar res√∫menes IA
Configura la API key de OpenRouter en `/home/g6/reto/imp-futuras/.env` para activar generaci√≥n autom√°tica de res√∫menes

### Cambiar modelo de embeddings
Edita `scripts/instalar_modelo.py` y `scripts/vectorizador.py`:
```python
# Opciones:
# - 'all-mpnet-base-v2' (ingl√©s, 768 dims)
# - 'paraphrase-multilingual-mpnet-base-v2' (multiling√ºe, 768 dims)
# - 'all-MiniLM-L6-v2' (ingl√©s, 384 dims, m√°s r√°pido)
MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'
```

### Configurar sincronizaci√≥n remota
Edita `setup.sh` o `sh_test/cp-vects.sh`:
```bash
MAQUINA_REMOTA="192.199.1.65"
RUTA_REMOTA="/home/g6/reto/datos"
```

## ü§ñ Automatizaci√≥n con Crontab

Ejecutar pipeline diario a las 2:00 AM:
```bash
crontab -e
```

A√±ade:
```cron
0 2 * * * cd /home/g6/reto/scraper && /home/g6/reto/scraper/.venv/bin/python scripts/run_pipeline.py >> /home/g6/reto/scraper/logs/cron.log 2>&1 && /home/g6/reto/scraper/.venv/bin/python scripts/vectorizador.py >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

O ejecuta el setup completo (verifica instalaciones + ejecuta pipeline):
```cron
0 2 * * * cd /home/g6/reto/scraper && bash setup.sh >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

## üìù Logs y Debugging

- `logs/scraper_metrics.log` ‚Üí Peticiones HTTP, latencias, errores de conexi√≥n (Fase 1)
- `logs/scraper_full_data_metrics.log` ‚Üí Peticiones HTTP, parseos exitosos (Fase 2)
- `logs/setup_fail.log` ‚Üí Fallos del instalador (setup.sh)
- Logs en consola: `tail -f logs/scraper_metrics.log`

## üîí Seguridad y Requisitos

- **SSH sin contrase√±a** requerido para sincronizaci√≥n remota (usa `ssh-copy-id 192.199.1.65`)
- **Espacio en disco**: ~4-5 GB (modelo + datos + cache pip/huggingface)
- **Python 3.8+** requerido
- **Librer√≠as CPU-only**: PyTorch sin CUDA para ahorrar espacio (~2 GB menos que versi√≥n GPU)

## üõ†Ô∏è Tecnolog√≠as

- **Scraping**: `requests` + `BeautifulSoup4`
- **Embeddings**: `sentence-transformers` (HuggingFace)
- **Modelo**: `paraphrase-multilingual-mpnet-base-v2` (278M par√°metros, 768 dims)
- **Backend ML**: PyTorch (CPU-only)
- **Res√∫menes IA**: OpenRouter (GPT-4o-mini) con parallelizaci√≥n
- **Formato de datos**: NDJSON (compatible con Filebeat/Logstash/Elasticsearch)
