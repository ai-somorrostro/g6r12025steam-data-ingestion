# Steam Scraper + VectorizaciÃ³n

Pipeline completo de scraping de juegos de Steam con generaciÃ³n automÃ¡tica de embeddings semÃ¡nticos y sincronizaciÃ³n remota para anÃ¡lisis RAG (Retrieval-Augmented Generation).

## ðŸŽ¯ Â¿QuÃ© hace este proyecto?

1. **Scraping inteligente**: Descarga datos de ~5,000 juegos de Steam (trending + clÃ¡sicos populares)
2. **Filtrado automÃ¡tico**: Elimina DLC, soundtracks y contenido adulto (filter-games.py)
3. **ExtracciÃ³n de descripciones**: Obtiene descripciones detalladas de la Steam API (imp-futuras)
4. **ResÃºmenes IA**: Genera resÃºmenes con OpenRouter GPT-4o-mini (imp-futuras)
5. **Reemplazo inteligente**: Integra descripciones resumidas en los datos principales (desc-changer.py)
6. **VectorizaciÃ³n semÃ¡ntica**: Genera embeddings de 768 dimensiones con modelos multilingÃ¼es para bÃºsqueda por similitud
7. **Pipeline automatizado**: Orquesta todas las fases â†’ limpieza â†’ vectorizaciÃ³n â†’ sincronizaciÃ³n remota
8. **SincronizaciÃ³n SSH**: Copia automÃ¡tica de datos vectorizados y logs a servidor remoto para ingestiÃ³n en Elasticsearch/Logstash

## ðŸ“ Estructura del Proyecto

```
scraper/
â”œâ”€â”€ scripts/                       # Scripts del pipeline
â”‚   â”œâ”€â”€ run_pipeline.py            # Orquestador principal (scraping â†’ limpieza)
â”‚   â”œâ”€â”€ gameid-script.py           # Fase 1: Descarga IDs de juegos populares
â”‚   â”œâ”€â”€ sacar-datos-games.py       # Fase 2: Obtiene detalles completos (identificador de IDs ya procesados) + limpieza HTML
â”‚   â”œâ”€â”€ filter-games.py            # Fase 2.5: Filtra DLC, soundtracks y contenido adulto
â”‚   â”œâ”€â”€ clean-tags.py              # Fase 3: Limpia categorÃ­as/tags irrelevantes
â”‚   â”œâ”€â”€ desc-changer.py            # Fase 3.5: Reemplaza descripciones con resÃºmenes IA
â”‚   â”œâ”€â”€ vectorizador.py            # Fase 4: Genera embeddings (768 dims)
â”‚   â””â”€â”€ instalar_modelo.py         # Descargador de modelos SentenceTransformers
â”œâ”€â”€ sh_test/                       # Scripts auxiliares
â”‚   â””â”€â”€ cp-vects.sh                # SincronizaciÃ³n manual a servidor remoto
â”œâ”€â”€ data/                          # Datos generados (ignorados por git)
â”‚   â”œâ”€â”€ steam-top-games.json       # IDs de juegos filtrados (5,001+)
â”‚   â”œâ”€â”€ steam-games-data.ndjson    # Datos completos con descripciones resumidas
â”‚   â””â”€â”€ steam-games-data-vect.ndjson # Datos + embeddings 768-dim (listo para RAG)
â”œâ”€â”€ backups/                       # Copias de seguridad (ej. steam-top-games-*.json)
â”œâ”€â”€ logs/                          # Logs del pipeline (ignorados por git)
â”‚   â”œâ”€â”€ scraper_metrics.log        # Logs de gameid-script.py
â”‚   â”œâ”€â”€ scraper_full_data_metrics.log # Logs de sacar-datos-games.py
â”‚   â””â”€â”€ setup_fail.log             # Registro de fallos del instalador
â”œâ”€â”€ .vscode/                       # ConfiguraciÃ³n local del editor
â”œâ”€â”€ setup.sh                       # Instalador completo Linux (ejecuta pipeline)
â”œâ”€â”€ requirements.txt               # Dependencias (requests, beautifulsoup4, torch CPU, sentence-transformers, openai, etc.)
â”œâ”€â”€ .gitignore                     # Ignora data/, logs/, .venv/, caches
â””â”€â”€ README.md                      # Este archivo
```

## ðŸš€ InstalaciÃ³n RÃ¡pida

### Linux/Mac (Setup completo)
```bash
cd /home/g6/reto/scraper
chmod +x setup.sh
./setup.sh
```

**El script `setup.sh` ejecuta automÃ¡ticamente:**
1. âœ… VerificaciÃ³n de Python3 disponible
2. âœ… **Uso del venv global unificado** (`/home/g6/.venv`) - compartido con imp-futuras
3. âœ… InstalaciÃ³n de dependencias desde `requirements.txt` (torch CPU, sentence-transformers, openai)
4. âœ… VerificaciÃ³n de PyTorch CPU + sentence-transformers mediante import check
5. âœ… Descarga del modelo de embeddings (paraphrase-multilingual-mpnet-base-v2, con verificaciÃ³n de cachÃ© en `~/.cache/huggingface/`)
6. âœ… **SincronizaciÃ³n de datos con Elasticsearch** (fase nueva)
7. âœ… Scraping de Steam (run_pipeline.py)
8. âœ… Filtrado de DLC/soundtracks (filter-games.py)
9. âœ… Limpieza de categorÃ­as Steam (clean-tags.py)
10. âœ… ExtracciÃ³n de descripciones + resÃºmenes IA (flux.sh en imp-futuras)
11. âœ… Reemplazo de descripciones (desc-changer.py)
12. âœ… VectorizaciÃ³n semÃ¡ntica (vectorizador.py)
13. âœ… **SincronizaciÃ³n incremental de datos** (cargar IDs existentes, eliminar obsoletos, reprocesar vÃ¡lidos)
14. âœ… SincronizaciÃ³n SSH a servidor remoto con validaciÃ³n de directorio (`192.199.1.65:/home/g6/reto/datos/`)

### InstalaciÃ³n manual (paso a paso)

Si prefieres instalar manualmente:

```bash
# 1. Usar entorno virtual global (crear si no existe)
python3 -m venv /home/g6/.venv
source /home/g6/.venv/bin/activate

# 2. Instalar dependencias (incluye torch CPU, sentence-transformers, openai)
cd /home/g6/reto/scraper
pip install -r requirements.txt

# 3. Verificar instalaciÃ³n de librerÃ­as crÃ­ticas
python -c "import torch, sentence_transformers, openai; print('âœ… OK')"

# 4. Descargar modelo de embeddings (si no estÃ¡ en cachÃ©)
python scripts/instalar_modelo.py
```

### ActualizaciÃ³n de un entorno existente

Si ya tienes `/home/g6/.venv` pero necesitas actualizar dependencias:

```bash
source /home/g6/.venv/bin/activate
cd /home/g6/reto/scraper
pip install --upgrade -r requirements.txt
```

## â–¶ï¸ EjecuciÃ³n del Pipeline

### EjecuciÃ³n completa (recomendado)
```bash
source /home/g6/.venv/bin/activate
python scripts/run_pipeline.py  # Scraping + limpieza
terminal -> /home/g6/reto/imp-futuras/flux.sh # Ejecucion del flujo (Resumenes LLM)
python scripts/desc-changer.py  # Cambio de descripciones viejas a nuevas
python scripts/vectorizador.py  # GeneraciÃ³n de embeddings
bash sh_test/cp-vects.sh        # SincronizaciÃ³n remota (opcional)
```

### EjecuciÃ³n individual de scripts

**Fase 1: Obtener IDs de juegos**
```bash
python scripts/gameid-script.py
# Salida: data/steam-top-games.json (~5k IDs)
```

**Fase 2: Descargar datos completos**
```bash
python scripts/sacar-datos-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-games-data.ndjson (tÃ­tulo, descripciÃ³n, gÃ©neros, precio, etc.)
# 
# Cambios recientes:
# - SincronizaciÃ³n incremental: Compara IDs con archivo NDJSON existente
# - Elimina juegos obsoletos (ya no en top games)
# - Reprocesa todos los vÃ¡lidos para actualizar precios/mÃ©tricas
# - Log de cambios: "SINCRONIZACIÃ“N | Eliminados:X | A reprocesar:Y"
```

**Fase 2.5: Filtrar DLC, soundtracks y contenido adulto**
```bash
python scripts/filter-games.py
# Entrada: data/steam-top-games.json
# Salida: data/steam-top-games-filtered.json (+ backup en backups/)
```

**Fase 3: ExtracciÃ³n de descripciones y generaciÃ³n de resÃºmenes IA (flux.sh)**
```bash
cd /home/g6/reto/imp-futuras
bash flux.sh  # Usa el mismo venv global /home/g6/.venv
# Salida: resÃºmenes IA en imp-futuras/data que luego usa desc-changer.py
```

**Fase 3.5: Reemplazar descripciones con resÃºmenes IA**
```bash
python scripts/desc-changer.py
# Entrada: data/steam-games-data.ndjson + resÃºmenes IA de imp-futuras
# Salida: data/steam-games-data.ndjson (actualizado con resÃºmenes)
```

**Fase 4: Generar embeddings**
```bash
python scripts/vectorizador.py
# Entrada: data/steam-games-data.ndjson
# Salida: data/steam-games-data-vect.ndjson (+ campo vector_embedding: float[768])
```

## ðŸ§­ Orden del pipeline (setup.sh)

1) VerificaciÃ³n de Python + venv global `/home/g6/.venv`
2) InstalaciÃ³n/verificaciÃ³n de dependencias (torch CPU, sentence-transformers, openai)
3) Descarga/validaciÃ³n del modelo de embeddings (cache HF)
4) `run_pipeline.py` â†’ gameid-script.py + sacar-datos-games.py (con sincronizaciÃ³n incremental)
5) `filter-games.py` â†’ filtra DLC/adulto y guarda `steam-top-games-filtered.json`
6) `imp-futuras/flux.sh` â†’ genera resÃºmenes IA (OpenRouter)
7) `desc-changer.py` â†’ inserta resÃºmenes IA en NDJSON principal
8) `clean-tags.py` â†’ limpia categorÃ­as/tags irrelevantes
9) `vectorizador.py` â†’ genera embeddings 768D
10) `scp` opcional â†’ sincroniza NDJSON vectorizado + logs a 192.199.1.65

## ðŸ“Š Formato de Salida (NDJSON)

Cada juego en `steam-games-data-vect.ndjson` es una lÃ­nea JSON con:

```json
{
  "appid": 730,
  "name": "Counter-Strike 2",
  "scraped_at": "2025-12-10 08:20:50",
  "price_eur": 0.00,
  "price_initial_eur": 0.0, 
  "discount_pct": 0,
  "metacritic_score": 0, // no tiene score
  "recommendations_total": 4810260,
  "achievements_count": 1, 
  "is_free": true,
  "genres": ["Action", "FPS"],
  "categories": ["FPS", "Disparos", "Multijugador", "Competitivos" ...], 
  "developers": ["Valve"], 
  "publishers": ["Valve"], 
  "achievements_list": ["Una nueva era"],
  "short_description": "For over two decades...",
  "detailed_description": "Counter-Strike 2 es un videojuego de disparos competitivo...",
  "vector_embedding": [0.0234, -0.1234, ..., 0.0567]  // 768 floats
}

```

**Campo clave:** `vector_embedding` â†’ Vector de 768 dimensiones para bÃºsqueda semÃ¡ntica en Elasticsearch con modelo dense_vector.

**Nota:** `detailed_description` ahora contiene un resumen IA generado con OpenRouter GPT-4o-mini (mÃ¡s conciso que la descripciÃ³n original).

## ðŸ”§ ConfiguraciÃ³n

### Entorno Virtual Global

El proyecto utiliza un **venv unificado** en `/home/g6/.venv` compartido entre `scraper` e `imp-futuras`:

```bash
# Activar siempre desde aquÃ­
source /home/g6/.venv/bin/activate

# LocalizaciÃ³n de binarios Python
/home/g6/.venv/bin/python
/home/g6/.venv/bin/pip

# CachÃ© de modelos HuggingFace
~/.cache/huggingface/hub/  # (descargado automÃ¡ticamente)
```

**Ventajas:**
- âœ… Una Ãºnica instalaciÃ³n de librerÃ­as pesadas (torch, transformers)
- âœ… Ahorra ~3-4 GB de espacio en disco
- âœ… Coherencia en versiones entre scraper e API
- âœ… Facilita mantenimiento centralizado

### SincronizaciÃ³n Incremental de Datos

El script `sacar-datos-games.py` implementa sincronizaciÃ³n inteligente:

```python
# Fase automÃ¡tica en cada ejecuciÃ³n:
1. cargar_ids_desde_ndjson()
   - Lee IDs existentes en steam-games-data.ndjson
   - Retorna set de IDs para comparaciÃ³n

2. sincronizar_datos(lista_entrada, archivo_salida)
   - Compara IDs nuevos vs existentes
   - Elimina registros de juegos que bajaron del top
   - Reprocesa TODO juegos vÃ¡lidos (actualizar precios/mÃ©tricas)
   - Log de cambios realizados

# Resultado:
- Archivo NDJSON siempre contiene juegos del top actual
- Precios siempre actualizados (ninguno es saltado)
- Juegos obsoletos eliminados automÃ¡ticamente
```

### Ajustar cantidad de juegos
- `scripts/gameid-script.py` â†’ `CANTIDAD_POR_CRITERIO = 5000` (IDs por criterio)
- `scripts/sacar-datos-games.py` â†’ `CANTIDAD_A_PROCESAR = 0` (0 = todos, cambiar a X para pruebas)

### Palabras clave para filtrado
Edita `scripts/filter-games.py` para cambiar quÃ© se filtra (DLC, soundtracks, etc.)

### Configurar resÃºmenes IA
Configura la API key de OpenRouter en `/home/g6/reto/imp-futuras/.env` para activar generaciÃ³n automÃ¡tica de resÃºmenes

### Cambiar modelo de embeddings
Edita `scripts/instalar_modelo.py` y `scripts/vectorizador.py`:
```python
# Opciones:
# - 'all-mpnet-base-v2' (inglÃ©s, 768 dims)
# - 'paraphrase-multilingual-mpnet-base-v2' (multilingÃ¼e, 768 dims) â† ACTUAL
# - 'all-MiniLM-L6-v2' (inglÃ©s, 384 dims, mÃ¡s rÃ¡pido)
MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'
```

### Configurar sincronizaciÃ³n remota
Edita `setup.sh` o `sh_test/cp-vects.sh`:
```bash
MAQUINA_REMOTA="192.199.1.65"
RUTA_REMOTA="/home/g6/reto/datos"
```

## ðŸ¤– AutomatizaciÃ³n con Crontab

Ejecutar pipeline diario a las 2:00 AM:
```bash
crontab -e
```

AÃ±ade:
```cron
0 2 * * * cd /home/g6/reto/scraper && /home/g6/.venv/bin/python scripts/run_pipeline.py >> /home/g6/reto/scraper/logs/cron.log 2>&1 && /home/g6/.venv/bin/python scripts/vectorizador.py >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

O ejecuta el setup completo (verifica instalaciones + ejecuta pipeline):
```cron
0 2 * * * cd /home/g6/reto/scraper && bash setup.sh >> /home/g6/reto/scraper/logs/cron.log 2>&1
```

## ðŸ“ Logs y Debugging

- `logs/scraper_metrics.log` â†’ Peticiones HTTP, latencias, errores de conexiÃ³n (Fase 1)
- `logs/scraper_full_data_metrics.log` â†’ Peticiones HTTP, parseos exitosos (Fase 2)
- `logs/setup_fail.log` â†’ Fallos del instalador (setup.sh)
- Logs en consola: `tail -f logs/scraper_metrics.log`

## ðŸ”’ Seguridad y Requisitos

- **SSH sin contraseÃ±a** requerido para sincronizaciÃ³n remota (usa `ssh-copy-id 192.199.1.65`)
- **Espacio en disco**: ~5-6 GB (venv global 2GB + modelo 470MB + datos 2-3GB)
- **Python 3.8+** requerido (testeado con Python 3.12.3)
- **Venv global**: `/home/g6/.venv` **obligatorio** - compartido entre scraper e imp-futuras
- **LibrerÃ­as CPU-only**: PyTorch sin CUDA para ahorrar espacio (~4 GB menos que versiÃ³n GPU)
- **Modelos en cachÃ©**: `~/.cache/huggingface/hub/` se crea automÃ¡ticamente (~470MB)

## ðŸ› ï¸ TecnologÃ­as

- **Scraping**: `requests` + `BeautifulSoup4`
- **Embeddings**: `sentence-transformers` (HuggingFace)
- **Modelo**: `paraphrase-multilingual-mpnet-base-v2` (278M parÃ¡metros, 768 dims)
- **Backend ML**: PyTorch (CPU-only)
- **ResÃºmenes IA**: OpenRouter (GPT-4o-mini) con parallelizaciÃ³n
- **Formato de datos**: NDJSON (compatible con Filebeat/Logstash/Elasticsearch)


# Para Â¡Â¡Â¡ VALIDACION !!!

- **Cambiar nombre de el .env.example  --->  .env  (/imp-futuras)**
- **poner API KEY de Openrouter en el .env**
- Cambiar en el archivo **/scraper/scripts/sacar-datos-games.py**
  
```python

# 0 = PROCESAR TODOS. Pon un nÃºmero bajo (ej: 50) para validacion.
CANTIDAD_A_PROCESAR = 0 # --> 50

```

- Cambiar en el archivo **/scraper/scripts/gameid-scripts**

```python

# 5000 de cada tipo para asegurar variedad (Para Validacion poner 50 en los 2 primeros)
CANTIDAD_POR_CRITERIO = 5000  # --> 50
RESULTADOS_POR_PAGINA = 50 
TIMEOUT = 30
MAX_REINTENTOS = 3

```

- Por ultimo darle permisos al **setup.sh** y ejecutarlo

```bash

chmod 777 scraper/setup.sh
./setup.sh

```
